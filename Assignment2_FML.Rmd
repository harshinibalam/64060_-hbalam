---
title: "Assignment 2"
author: "Harshini Balam"
date: "2024-02-25"
output:
  pdf_document: default
  html_document: default
---

#Summary
The assignment’s objective is to predict, using KNN(k-Nearest Neighbors)Classification, if the loan offer will be accepted by consumers of Universal Bank. The data set contains demographic information about the customers as well as other silent-related information. Following the reading of the data set and the installation of the required libraries, extra columns are removed, category categories are changed to dummy variables, and the data is eventually normalized. Following that, the data set was divided into two sets:training and validation, each of which contained 60% and 40% of the entire data. A new consumer was categorized as either accepting or rejecting a loan offer using k-NN with k=1.By assessing accuracy on the validation set, the optimal k value—which strikes a balance between over fitting and under      fitting—was found, with k=1 being the result.
```{r}
library(caret)
```

```{r}
library(ISLR)
library(dplR)
```

```{r}
library('class')
library('gmodels')
library('FNN')
```

```{r}
library("ggplot2")
```

*Import dataset UniversalBank.csv*

```{r}
setwd("C:\\Users\\Harshini\\OneDrive - Kent State University\\Fundementals of Machine Learning")
UniversalBank=read.csv("UniversalBank.csv")
head(UniversalBank)
```

```{r}
colnames(UniversalBank)
```
*Summary of UniversalBank dataset*

```{r}
summary(UniversalBank)
```
*Making columns ID and ZIP.Code as NULL*

```{r}
UniversalBank$ID <- NULL
UniversalBank$ZIP.Code <- NULL
summary(UniversalBank)
```
*Making the Personal Loan column as factor*

```{r}
UniversalBank$Personal.Loan= as.factor(UniversalBank$Personal.Loan)
```

*Normalization*

```{r}
Normal_Data <- preProcess(UniversalBank,method = "range")
UniversalBank_Norm <- predict(Normal_Data,UniversalBank)
summary(UniversalBank_Norm)
```
*Partition the data into training 60% and validation 40% sets*

```{r}
Train_index <- createDataPartition(UniversalBank$Personal.Loan, p = 0.6, list = FALSE)
train.df =UniversalBank_Norm[Train_index,]
validation.df = UniversalBank_Norm[-Train_index,]
```

*Classifying the customer as per the date provided*

```{r}
To_Predict = data.frame(Age = 40,  Experience = 10, Income = 84, Family = 2,
CCAvg = 2, Education = 1, Mortgage = 0, Securities.Account = 0, CD.Account = 0,
Online = 1, CreditCard = 1)
print(To_Predict)
```
```{r}
Prediction <- knn(train = train.df[,1:7],test = To_Predict[,1:7],
cl = train.df$Personal.Loan, k = 1)
print(Prediction)

```
*Customer is classified as 1.*

*2) What is the choice of k that balances between overfitting and ignoring the predictor information?*

```{r}
set.seed(2808)
UniversalBank_control <- trainControl(method = "repeatedcv", number =5, repeats = 2)
searchGrid = expand.grid(k=1:10)
knn.model = train(Personal.Loan~., data = train.df, method = 'knn', tuneGrid = searchGrid, trControl = UniversalBank_control)
knn.model
```
*The choice of K that balances between overfitting and ignoring predictors K=1*

```{r}
plot(knn.model, type = "b", xlab = "K-Value", ylab = "Accuracy")
```
#finding the best K 

```{r}
best_k <- knn.model$bestTune[[1]]
best_k
```
*3) Show the confusion matrix for the validation data that results from using the best k.*

```{r}
predictions <- predict(knn.model,validation.df)
confusionMatrix(predictions,validation.df$Personal.Loan)

```
***4) Classify the customer using the best k***

```{r}
To_Predict_Normaliz = data.frame(Age = 40, Experience = 10, Income = 84,
Family = 2,CCAvg = 2, Education = 1, Mortgage = 0,Securities.Account =0,
CD.Account = 0, Online = 1,CreditCard = 1)
To_Predict_Normaliz = predict(Normal_Data, To_Predict)
predict(knn.model, To_Predict_Normaliz)

```
***5) Repartition the data into 50% for training ,30% for validation, 20% for test***

```{r}
train_size = 0.5
Train_index = createDataPartition(UniversalBank$Personal.Loan, p = 0.5,
list = FALSE)
train.df = UniversalBank_Norm[Train_index,]
test_size = 0.2
Test_index = createDataPartition(UniversalBank$Personal.Loan, p = 0.2,
list = FALSE)
Test.df = UniversalBank_Norm[Test_index,]
valid_size = 0.3
Validation_index = createDataPartition(UniversalBank$Personal.Loan, p = 0.3,
list = FALSE)
validation.df = UniversalBank_Norm[Validation_index,]
Testingknn <- knn(train = train.df[,-8], test = Test.df[,-8], cl = train.df[,8],
k =3)
Validationknn <- knn(train = train.df[,-8],
test = validation.df[,-8], cl = train.df[,8], k =3)
Trainingknn <- knn(train = train.df[,-8],
test = train.df[,-8], cl = train.df[,8], k =3)
```

***Comparing the confusion matrix of the test set with the training and validation sets.***

```{r}
confusionMatrix(Testingknn, Test.df[,8])

```
```{r}
confusionMatrix(Trainingknn, train.df[,8])
```

